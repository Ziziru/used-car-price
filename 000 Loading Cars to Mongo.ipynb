{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps to loading file into Tabelue\n",
    "#1. start-all in \n",
    "#2. Run MongoSQLD\n",
    "#3. run below code in cmd \n",
    "#pyspark --conf \"spark.mongodb.input.uri=mongodb://127.0.0.1/dbase.quakes?readPreference=primaryPrefered\" --conf \"spark.mongodb.output.uri=mongodb://127.0.0.1/dbase.quakes\" --packages org.mongodb.spark:mongo-spark-connector_2.12:2.4.1\n",
    "#4. put csv in bigdata folder. Open Cmd, type; hdfs dfs -ls /hdfs dfs -mkdir /class hdfs dfs -copyFromLocal C:/bigdata_class/car_data.csv /class hdfs dfs -ls \n",
    "#5. Upload this Jupyter note, run all the code\n",
    "#6. Refresh NoSQL Mongodb Test connection with ODBC \n",
    "#7. Open in tableu under servers\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.sql(\"select 'spark' as hello\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder\\\n",
    "        .master('local[2]')\\\n",
    "        .appName('quake_etl')\\\n",
    "        .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:2.4.1')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code above reused from Material 12's spark-mongodb Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- #: integer (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Mileage: string (nullable = true)\n",
      " |-- Price: string (nullable = true)\n",
      " |-- Manufacturer's Suggested Retail Price: string (nullable = true)\n",
      " |-- Price - MSRP: string (nullable = true)\n",
      " |-- Brand: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loading our data set from the big_data folder, needs Hadoop commands to load \n",
    "df_load = spark.read.csv('/class/bcar.csv',inferSchema=True, header=True)\n",
    "df_load.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car = df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----+------+-------------+--------+-------------------------------------+------------+-----+\n",
      "|  #|               Model|Year|Status|      Mileage|   Price|Manufacturer's Suggested Retail Price|Price - MSRP|Brand|\n",
      "+---+--------------------+----+------+-------------+--------+-------------------------------------+------------+-----+\n",
      "|  0|2023 Acura RDX A-...|2023|   New|Not available|50895.00|                        Not specified|     #VALUE!|Acura|\n",
      "|  1|2023 Acura TLX Ty...|2023|   New|Not available|57745.00|                        Not specified|     #VALUE!|Acura|\n",
      "|  2|2023 Acura TLX Ty...|2023|   New|Not available|57545.00|                        Not specified|     #VALUE!|Acura|\n",
      "|  3|2023 Acura TLX Ty...|2023|   New|Not available|57745.00|                        Not specified|     #VALUE!|Acura|\n",
      "|  4|2023 Acura TLX A-...|2023|   New|Not available|47995.00|                        Not specified|     #VALUE!|Acura|\n",
      "+---+--------------------+----+------+-------------+--------+-------------------------------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_car.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car.write.format('mongo')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('spark.mongodb.output.uri', 'mongodb://127.0.0.1:27017/dbase.quakes').save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
